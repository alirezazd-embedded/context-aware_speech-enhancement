# -*- coding: utf-8 -*-
"""Keras_Bin_Classifier

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p-3F6faWrgDelc4bhzEPlmum1_mhpyCV
"""

import math
import sys
import numpy as np
np.set_printoptions(threshold=sys.maxsize)
import random
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import tensorflow as tf
import numpy as np
from tensorflow import keras
import os
import csv
import itertools
import requests

def normalize(data, max):
  return np.divide(data, max)

if not(os.path.exists('Dataset.csv')):
  r = requests.get('https://drive.google.com/uc?export=download&id=1mcCD6h0gdVgQD9m_ylmR_XDPY2HYgJRW', allow_redirects=True)
  open('Dataset.csv', 'wb').write(r.content)
with open('Dataset.csv', newline='') as f:
    reader = csv.reader(f)
    trian_labels = list(reader)
trian_labels = trian_labels[0]
trian_labels = np.array(list(map(int, trian_labels)))
trian_labels = trian_labels.astype(np.float32)
input_snr = normalize(np.array(np.linspace(0, 20, 5)),20)
input_snr = input_snr.astype(np.float32)
input_snr2 = np.power(input_snr,2)
noise_type = normalize(np.array(np.arange(0, 5, step = 1)),4)
noise_type = noise_type.astype(np.float32)
train_datas = np.array(list(itertools.product(noise_type, input_snr)))
train_datas = np.column_stack((train_datas[:,0], train_datas[:,1], np.power(train_datas[:,1], 2)))

model = keras.Sequential([
    keras.layers.Dense(3, activation = 'elu', name="input"),
    keras.layers.Dense(1, name="output")
])
model.compile(optimizer='adam', loss = tf.keras.losses.BinaryCrossentropy(reduction = 'sum',from_logits = True), metrics=tf.keras.metrics.BinaryAccuracy(threshold=0.5))

model.fit(train_datas, trian_labels, epochs=5000)

probability_model = tf.keras.Sequential([model])
predictions = probability_model.predict(train_datas)
np.reshape(predictions,(5,5)) 
fig = plt.figure() 
ax = fig.add_subplot(111)
ax.axis([-0.1,1.1,-0.1,1.1])
ax.scatter(train_datas[:,1], train_datas[:,0], s = 25, c = trian_labels, cmap = cm.bwr)
plt.xlabel('Noise level dB/20')
plt.ylabel('Noise type')
fig = plt.figure()
ax = fig.add_subplot(111)
ax.axis([-0.1,1.1,-0.1,1.1])
ax.scatter(train_datas[:,1], train_datas[:,0], s = 25, c = predictions, cmap = cm.bwr)
plt.xlabel('Noise level dB')
plt.ylabel('Noise type')
predictions = np.greater(predictions,0.5)
fig = plt.figure()
ax = fig.add_subplot(111)
ax.axis([-0.1,1.1,-0.1,1.1])
ax.scatter(train_datas[:,1], train_datas[:,0], s = 25, c = predictions, cmap = cm.bwr)
plt.xlabel('Noise level dB')
plt.ylabel('Noise type')
fig.canvas.draw()
test_loss, test_acc = model.evaluate(train_datas,  trian_labels, verbose=2)

model.summary()
keras.models.save_model(model, 'model.keras.h5')
keras_model= tf.keras.models.load_model(filepath='model.keras.h5')
tflite_converter = tf.lite.TFLiteConverter.from_keras_model(keras_model)
tflite_model = tflite_converter.convert()
open('CLASSIFIER.tflite', 'wb').write(tflite_model)

interpreter = tf.lite.Interpreter(model_path="./CLASSIFIER.tflite")
interpreter.allocate_tensors()
print("all ok")
# Print input shape and type
inputs = interpreter.get_input_details()
print('{} input(s):'.format(len(inputs)))
for i in range(0, len(inputs)):
    print('{} {}'.format(inputs[i]['shape'], inputs[i]['dtype']))

# Print output shape and type
outputs = interpreter.get_output_details()
print('\n{} output(s):'.format(len(outputs)))
for i in range(0, len(outputs)):
    print('{} {}'.format(outputs[i]['shape'], outputs[i]['dtype']))