# -*- coding: utf-8 -*-
"""TF_Bin_Classifier

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o2XTDXP6MBKBAAPalJv7IVtm_R69tDrq
"""

import math
import sys
import numpy as np
np.set_printoptions(threshold=sys.maxsize)
import random
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import tensorflow as tf
from tensorflow import feature_column
import itertools
import csv
import pandas as pd
import requests
import os
print("Tensorflow Version: ", tf.__version__, "\nGPU: ", tf.config.list_physical_devices('GPU'))

classifier_dir =  "Classifier"

def demo(feature_column, data):
  feature_layer = layers.DenseFeatures(feature_column)
  print(feature_layer(data).numpy())

def input_fn(features, batch_size=240, shuffle = False):
  input_snr2 = np.power(features['input_snr'], 2)
  features['input_snr2'] = input_snr2.tolist()
  dataset = tf.data.Dataset.from_tensor_slices(dict(features))
  return dataset.batch(batch_size)

def trian_fn(features, labels, batch_size=240, epochs = 10000):
  input_snr2 = np.power(features['input_snr'], 2)
  features['input_snr2'] = input_snr2.tolist()
  dataset = tf.data.Dataset.from_tensor_slices((features, labels))
  dataset = dataset.shuffle(batch_size).repeat(epochs)
  return dataset.batch(batch_size)

if not(os.path.exists('Dataset.csv')):
  r = requests.get('https://drive.google.com/uc?export=download&id=1mcCD6h0gdVgQD9m_ylmR_XDPY2HYgJRW', allow_redirects=True)
  open('Dataset.csv', 'wb').write(r.content)
with open('Dataset.csv', newline='') as f:
    reader = csv.reader(f)
    trian_labels = list(reader)
trian_labels = trian_labels[0]
trian_labels = np.array(list(map(int, trian_labels)))
trian_labels = trian_labels.astype(np.float32)
test_labels = np.zeros(10, dtype=int)
input_snr = np.array(np.linspace(0, 15, 16))
input_snr = input_snr.astype(np.float32)
noise_type = np.array(np.arange(0, 15, step = 1))
noise_type = noise_type.astype(np.uint8)
input_iterations = np.array(list(itertools.product(noise_type, input_snr)))
noise_types = tf.feature_column.numeric_column("noise_type", dtype = tf.float32)
input_snrs = tf.feature_column.numeric_column("input_snr", dtype = tf.float32)
input_snrs2 = tf.feature_column.numeric_column("input_snr2", dtype = tf.float32)
train_datas = {'input_snr' : input_iterations[:,1], 'noise_type' : input_iterations[:,0]}
test_datas = {'input_snr' : (10, 10, 11, 11, 12, 12, 13, 13, 14, 14), 'noise_type' : (6, 7, 6, 7, 6, 7, 6, 7, 6, 7)}
#snr_buckets = tf.feature_column.bucketized_column(input_snrs, boundaries = [3, 6, 10, 13, 16])
features = [noise_types, input_snrs, input_snrs2]

classifier = tf.estimator.LinearClassifier(n_classes=2, model_dir = classifier_dir, feature_columns=features)

classifier.train(input_fn = lambda: trian_fn(features = train_datas, labels = trian_labels))

classifier.evaluate(input_fn = lambda: trian_fn(features = train_datas, labels = trian_labels, epochs = 1))
#Find a good Accuracy measure function

predictions_gen = classifier.predict(input_fn = lambda: input_fn(features = train_datas))
predictions = np.array([])
for p in predictions_gen: predictions = np.append(predictions, p['class_ids'])

print(predictions == trian_labels)
fig = plt.figure() 
ax = fig.add_subplot(111)
ax.axis([-1,16,-1,15])
ax.scatter(input_iterations[:,1], input_iterations[:,0], s = 25, c = trian_labels, cmap = cm.bwr)
plt.xlabel('Noise level dB')
plt.ylabel('Noise type')
fig = plt.figure() 
ax = fig.add_subplot(111)
ax.axis([-1,16,-1,15])
ax.scatter(input_iterations[:,1], input_iterations[:,0], s = 25, c = predictions, cmap = cm.bwr)
plt.xlabel('Noise level dB')
plt.ylabel('Noise type') 
fig.canvas.draw()

serving_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(tf.feature_column.make_parse_example_spec(features))
classifier.export_saved_model(classifier_dir+"\saved_model", serving_input_fn)

loaded = tf.saved_model.load("C:/Users/AliReza/Desktop/Classifier/saved_model", tags = None)
converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir = "C:/Users/AliReza/Desktop/Classifier/saved_model", signature_keys=['serving_default']) # path to the SavedModel directory
converter.experimental_new_converter = True
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]
tflite_model = converter.convert()
with open('model.tflite', 'wb') as f:
  f.write(tflite_model)

